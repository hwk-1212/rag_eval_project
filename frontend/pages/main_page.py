"""
ä¸»é¡µé¢ - Page 1
åŒ…å«ï¼šé…ç½®åŒºã€å¯¹è¯çª—å£ã€çŸ¥è¯†åº“ç®¡ç†
"""
import streamlit as st
import requests
from datetime import datetime
from frontend.components.sidebar import render_config_section, render_knowledge_base_section

API_BASE_URL = "http://localhost:8000/api/v1"


def render_main_page():
    """
    ä¸»é¡µé¢å¸ƒå±€ï¼š
    - é¡¶éƒ¨ï¼šé…ç½®åŒºï¼ˆLLMã€RAGã€è¯„ä¼°ï¼‰
    - ä¸­é—´ï¼šå¯¹è¯çª—å£
    - åº•éƒ¨ï¼šçŸ¥è¯†åº“é€‰æ‹©å’Œæ–‡æ¡£ç®¡ç†
    """
    
    # ========== é¡¶éƒ¨é…ç½®åŒº ==========
    with st.expander("âš™ï¸ é…ç½®åŒº", expanded=False):
        config_col1, config_col2, config_col3 = st.columns(3)
        
        # LLMé…ç½®
        with config_col1:
            st.markdown("### ğŸ¤– LLMé…ç½®")
            render_llm_config()
        
        # RAGæŠ€æœ¯é€‰æ‹©
        with config_col2:
            st.markdown("### ğŸ”§ RAGæŠ€æœ¯é€‰æ‹©")
            render_rag_selection()
        
        # è¯„ä¼°é…ç½®
        with config_col3:
            st.markdown("### ğŸ“Š è¯„ä¼°é…ç½®")
            render_eval_config()
    
    st.markdown("---")
    
    # ========== ä¸­é—´å¯¹è¯çª—å£ ==========
    st.markdown("### ğŸ’¬ å¯¹è¯çª—å£")
    
    render_chat_window()
    
    st.markdown("---")
    
    # ========== åº•éƒ¨çŸ¥è¯†åº“ç®¡ç† ==========
    st.markdown("### ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
    
    kb_col1, kb_col2 = st.columns([3, 7])
    
    with kb_col1:
        # ç™¾ç‚¼APIé…ç½®
        with st.expander("ğŸ”‘ APIå¯†é’¥é…ç½®", expanded=False):
            api_key = st.text_input(
                "ç™¾ç‚¼APIå¯†é’¥",
                value=st.session_state.get("api_key", ""),
                type="password",
                key="main_api_key"
            )
            if api_key != st.session_state.get("api_key"):
                st.session_state.api_key = api_key
                st.success("APIå¯†é’¥å·²æ›´æ–°")
        
        # æ¨¡å‹é€‰æ‹©
        with st.expander("ğŸ¯ æ¨¡å‹é€‰æ‹©", expanded=False):
            model_options = ["qwen-plus", "qwen-turbo", "qwen-max", "gpt-4", "gpt-3.5-turbo"]
            selected_model = st.selectbox(
                "é€‰æ‹©LLMæ¨¡å‹",
                options=model_options,
                index=0,
                key="main_model_select"
            )
            st.session_state.selected_model = selected_model
    
    with kb_col2:
        # çŸ¥è¯†åº“é€‰æ‹©å’Œæ–‡æ¡£ç®¡ç†
        render_knowledge_base_section()


def render_llm_config():
    """LLMé…ç½®åŒº"""
    # åˆå§‹åŒ–LLMé…ç½®
    if "llm_config" not in st.session_state:
        st.session_state.llm_config = {
            "model": "qwen-plus",
            "temperature": 0.7,
            "max_tokens": 2000
        }
    
    llm_config = st.session_state.llm_config
    
    llm_config["temperature"] = st.slider(
        "Temperature",
        min_value=0.0,
        max_value=1.0,
        value=llm_config.get("temperature", 0.7),
        step=0.1,
        key="llm_temp"
    )
    
    llm_config["max_tokens"] = st.number_input(
        "Max Tokens",
        min_value=100,
        max_value=4000,
        value=llm_config.get("max_tokens", 2000),
        step=100,
        key="llm_tokens"
    )
    
    st.caption(f"æ¨¡å‹: {llm_config.get('model', 'qwen-plus')}")


def render_rag_selection():
    """RAGæŠ€æœ¯é€‰æ‹©åŒºï¼ˆç´§å‡‘ç‰ˆï¼‰"""
    if "selected_rag_techniques" not in st.session_state:
        st.session_state.selected_rag_techniques = ["simple_rag"]
    
    rag_techniques = {
        "simple_rag": "Simple RAG",
        "reranker_rag": "Reranker RAG",
        "fusion_rag": "Fusion RAG",
        "hyde_rag": "HyDE RAG",
        "contextual_compression_rag": "Compression",
        "query_transformation_rag": "Query Transform",
        "adaptive_rag": "Adaptive RAG",
        "self_rag": "Self RAG",
        "crag": "CRAG",
        "context_enriched_rag": "Context Enriched",
        "contextual_chunk_headers_rag": "Chunk Headers",
        "hierarchical_rag": "Hierarchical",
        "doc_augmentation_rag": "Doc Augmentation",
        "semantic_chunking_rag": "Semantic Chunking",
        "rse_rag": "RSE",
        "chunk_size_selector_rag": "Chunk Size Selector",
        "proposition_chunking_rag": "Proposition",
        "graph_rag": "Graph RAG",
    }
    
    # å¤šé€‰æ¡†ï¼ˆç´§å‡‘æ˜¾ç¤ºï¼‰
    selected = st.multiselect(
        "é€‰æ‹©RAGæŠ€æœ¯",
        options=list(rag_techniques.keys()),
        default=st.session_state.selected_rag_techniques,
        format_func=lambda x: rag_techniques[x],
        key="rag_multiselect"
    )
    
    st.session_state.selected_rag_techniques = selected if selected else ["simple_rag"]
    
    # å¹¶å‘è®¾ç½®
    concurrent_num = st.slider(
        "å¹¶å‘æ•°",
        min_value=1,
        max_value=10,
        value=st.session_state.get("concurrent_num", 3),
        key="main_concurrent"
    )
    st.session_state.concurrent_num = concurrent_num
    
    st.caption(f"å·²é€‰æ‹© {len(st.session_state.selected_rag_techniques)} ä¸ªæŠ€æœ¯")


def render_eval_config():
    """è¯„ä¼°é…ç½®åŒº"""
    if "eval_config" not in st.session_state:
        st.session_state.eval_config = {
            "auto_eval_enabled": False,
            "use_ragas": False
        }
    
    eval_config = st.session_state.eval_config
    
    eval_config["auto_eval_enabled"] = st.checkbox(
        "æŸ¥è¯¢åè‡ªåŠ¨è¯„ä¼°",
        value=eval_config.get("auto_eval_enabled", False),
        key="auto_eval_check"
    )
    
    eval_config["use_ragas"] = st.checkbox(
        "ä½¿ç”¨Ragasè¯„ä¼°",
        value=eval_config.get("use_ragas", False),
        key="ragas_check"
    )
    
    if eval_config["auto_eval_enabled"]:
        st.success("âœ… è‡ªåŠ¨è¯„ä¼°å·²å¯ç”¨")
    else:
        st.info("â¸ï¸ æ‰‹åŠ¨è¯„ä¼°æ¨¡å¼")


def render_chat_window():
    """å¯¹è¯çª—å£"""
    # ä¼šè¯ä¿¡æ¯
    if st.session_state.current_session_id:
        st.caption(f"ğŸ“ ä¼šè¯ID: {st.session_state.current_session_id}")
    
    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    chat_container = st.container(height=400)
    
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if "timestamp" in message:
                    st.caption(message["timestamp"])
    
    # åº•éƒ¨æŒ‰é’®å’Œè¾“å…¥
    btn_col1, btn_col2, btn_col3 = st.columns([2, 2, 6])
    
    with btn_col1:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            st.session_state.messages = []
            st.session_state.rag_results = []
            st.rerun()
    
    with btn_col2:
        if st.button("ğŸ“Š æŸ¥çœ‹å¯¹æ¯”", use_container_width=True, type="primary"):
            st.info("ğŸ’¡ è¯·åˆ‡æ¢åˆ°ã€ŒRAGå¯¹æ¯”ã€é¡µé¢æŸ¥çœ‹è¯¦ç»†å¯¹æ¯”")
    
    with btn_col3:
        st.caption("ğŸ’¬ åœ¨ä¸‹æ–¹è¾“å…¥æ¡†æé—®")
    
    # è¾“å…¥æ¡†
    query = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")
    
    if query:
        handle_query(query)


def handle_query(query: str):
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    # éªŒè¯
    if not st.session_state.selected_documents:
        st.error("âŒ è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªæ–‡æ¡£")
        return
    
    if not st.session_state.selected_rag_techniques:
        st.error("âŒ è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªRAGæŠ€æœ¯")
        return
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.messages.append({
        "role": "user",
        "content": query,
        "timestamp": timestamp
    })
    
    # è°ƒç”¨åç«¯API
    with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒ..."):
        try:
            rag_config = st.session_state.get("rag_config", {})
            rag_config["concurrent_num"] = st.session_state.get("concurrent_num", 3)
            
            payload = {
                "query": query,
                "document_ids": st.session_state.selected_documents,
                "rag_techniques": st.session_state.selected_rag_techniques,
                "session_id": st.session_state.current_session_id,
                "llm_config": st.session_state.get("llm_config", {}),
                "rag_config": rag_config
            }
            
            response = requests.post(
                f"{API_BASE_URL}/qa/query",
                json=payload,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                
                # ä¿å­˜ä¼šè¯IDå’Œç»“æœ
                st.session_state.current_session_id = result["session_id"]
                st.session_state.rag_results = result["results"]
                
                # æ˜¾ç¤ºä¸»è¦å›ç­”
                if result["results"]:
                    main_answer = result["results"][0]["answer"]
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": main_answer,
                        "timestamp": timestamp
                    })
                    
                    st.success(f"âœ… å·²ä½¿ç”¨ {len(result['results'])} ç§RAGæŠ€æœ¯å®Œæˆå›ç­”")
                    
                    # å¦‚æœå¯ç”¨è‡ªåŠ¨è¯„ä¼°
                    if st.session_state.eval_config.get("auto_eval_enabled"):
                        st.info("ğŸ¤– æ­£åœ¨è¿›è¡Œè‡ªåŠ¨è¯„ä¼°...")
                    
                    st.rerun()
                else:
                    st.error("âŒ æœªè·å–åˆ°ä»»ä½•ç»“æœ")
            else:
                st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {response.text}")
                
        except requests.exceptions.Timeout:
            st.error("â±ï¸ è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        except Exception as e:
            st.error(f"âŒ æŸ¥è¯¢å‡ºé”™: {str(e)}")

